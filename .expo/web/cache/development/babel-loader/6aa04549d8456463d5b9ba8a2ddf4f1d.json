{"ast":null,"code":"import _defineProperty from \"@babel/runtime/helpers/defineProperty\";\nimport _toConsumableArray from \"@babel/runtime/helpers/toConsumableArray\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\n\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from \"./recorderHelpers\";\nvar isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\nvar AudioContext = window.AudioContext || window.webkitAudioContext;\nvar SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nvar recognition;\n\nif (navigator.brave) {\n  navigator.brave.isBrave().then(function (bool) {\n    if (bool) recognition = null;\n  });\n}\n\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\n\nexport default function useSpeechToText(_ref) {\n  var continuous = _ref.continuous,\n      crossBrowser = _ref.crossBrowser,\n      googleApiKey = _ref.googleApiKey,\n      googleCloudRecognitionConfig = _ref.googleCloudRecognitionConfig,\n      onStartSpeaking = _ref.onStartSpeaking,\n      onStoppedSpeaking = _ref.onStoppedSpeaking,\n      _ref$speechRecognitio = _ref.speechRecognitionProperties,\n      speechRecognitionProperties = _ref$speechRecognitio === void 0 ? {\n    interimResults: true\n  } : _ref$speechRecognitio,\n      _ref$timeout = _ref.timeout,\n      timeout = _ref$timeout === void 0 ? 10000 : _ref$timeout,\n      _ref$useOnlyGoogleClo = _ref.useOnlyGoogleCloud,\n      useOnlyGoogleCloud = _ref$useOnlyGoogleClo === void 0 ? false : _ref$useOnlyGoogleClo,\n      _ref$useLegacyResults = _ref.useLegacyResults,\n      useLegacyResults = _ref$useLegacyResults === void 0 ? true : _ref$useLegacyResults;\n\n  var _useState = useState(false),\n      _useState2 = _slicedToArray(_useState, 2),\n      isRecording = _useState2[0],\n      setIsRecording = _useState2[1];\n\n  var audioContextRef = useRef();\n\n  var _useState3 = useState([]),\n      _useState4 = _slicedToArray(_useState3, 2),\n      legacyResults = _useState4[0],\n      setLegacyResults = _useState4[1];\n\n  var _useState5 = useState([]),\n      _useState6 = _slicedToArray(_useState5, 2),\n      results = _useState6[0],\n      setResults = _useState6[1];\n\n  var _useState7 = useState(),\n      _useState8 = _slicedToArray(_useState7, 2),\n      interimResult = _useState8[0],\n      setInterimResult = _useState8[1];\n\n  var _useState9 = useState(''),\n      _useState10 = _slicedToArray(_useState9, 2),\n      error = _useState10[0],\n      setError = _useState10[1];\n\n  var timeoutId = useRef();\n  var mediaStream = useRef();\n  useEffect(function () {\n    var _navigator, _navigator$mediaDevic;\n\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n\n    if (!((_navigator = navigator) != null && (_navigator$mediaDevic = _navigator.mediaDevices) != null && _navigator$mediaDevic.getUserMedia)) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error('No google cloud API key was passed, google API will not be able to process speech');\n    }\n\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n\n    if (useLegacyResults) {\n      console.warn('react-hook-speech-to-text is using legacy results, pass useLegacyResults: false to the hook to use the new array of objects results. Legacy array of strings results will be removed in a future version.');\n    }\n  }, []);\n\n  var chromeSpeechRecognition = function chromeSpeechRecognition() {\n    if (recognition) {\n      if (continuous) recognition.continuous = true;\n\n      var _ref2 = speechRecognitionProperties || {},\n          grammars = _ref2.grammars,\n          interimResults = _ref2.interimResults,\n          lang = _ref2.lang,\n          maxAlternatives = _ref2.maxAlternatives;\n\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1;\n      recognition.start();\n\n      recognition.onresult = function (e) {\n        var result = e.results[e.results.length - 1];\n        var transcript = result[0].transcript;\n        var timestamp = Math.floor(Date.now() / 1000);\n\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults(function (prevResults) {\n              return [].concat(_toConsumableArray(prevResults), [{\n                transcript: transcript,\n                timestamp: timestamp\n              }]);\n            });\n            setLegacyResults(function (prevResults) {\n              return [].concat(_toConsumableArray(prevResults), [transcript]);\n            });\n          } else {\n            var concatTranscripts = '';\n\n            for (var i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults(function (prevResults) {\n            return [].concat(_toConsumableArray(prevResults), [{\n              transcript: transcript,\n              timestamp: timestamp\n            }]);\n          });\n          setLegacyResults(function (prevResults) {\n            return [].concat(_toConsumableArray(prevResults), [transcript]);\n          });\n        }\n      };\n\n      recognition.onaudiostart = function () {\n        return setIsRecording(true);\n      };\n\n      recognition.onend = function () {\n        setIsRecording(false);\n      };\n    }\n  };\n\n  var startSpeechToText = function _callee() {\n    var _audioContextRef$curr;\n\n    var _audioContextRef$curr2, stream, speechEvents;\n\n    return _regeneratorRuntime.async(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (!(!useOnlyGoogleCloud && recognition)) {\n              _context.next = 3;\n              break;\n            }\n\n            chromeSpeechRecognition();\n            return _context.abrupt(\"return\");\n\n          case 3:\n            if (!(!crossBrowser && !useOnlyGoogleCloud)) {\n              _context.next = 5;\n              break;\n            }\n\n            return _context.abrupt(\"return\");\n\n          case 5:\n            if (((_audioContextRef$curr = audioContextRef.current) == null ? void 0 : _audioContextRef$curr.state) === 'suspended') {\n              (_audioContextRef$curr2 = audioContextRef.current) == null ? void 0 : _audioContextRef$curr2.resume();\n            }\n\n            _context.next = 8;\n            return _regeneratorRuntime.awrap(startRecording({\n              errHandler: function errHandler() {\n                return setError('Microphone permission was denied');\n              },\n              audioContext: audioContextRef.current\n            }));\n\n          case 8:\n            stream = _context.sent;\n            setIsRecording(true);\n\n            if (timeout) {\n              clearTimeout(timeoutId.current);\n              handleRecordingTimeout();\n            }\n\n            if (mediaStream.current) {\n              stopMediaStream();\n            }\n\n            mediaStream.current = stream.clone();\n            speechEvents = Hark(mediaStream.current, {\n              audioContext: audioContextRef.current\n            });\n            speechEvents.on('speaking', function () {\n              if (onStartSpeaking) onStartSpeaking();\n              clearTimeout(timeoutId.current);\n            });\n            speechEvents.on('stopped_speaking', function () {\n              if (onStoppedSpeaking) onStoppedSpeaking();\n              stopRecording({\n                exportWAV: true,\n                wavCallback: function wavCallback(blob) {\n                  return handleBlobToBase64({\n                    blob: blob,\n                    continuous: continuous || false\n                  });\n                }\n              });\n            });\n\n          case 16:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, null, null, null, Promise);\n  };\n\n  var stopSpeechToText = function stopSpeechToText() {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: function wavCallback(blob) {\n          return handleBlobToBase64({\n            blob: blob,\n            continuous: false\n          });\n        }\n      });\n    }\n  };\n\n  var handleRecordingTimeout = function handleRecordingTimeout() {\n    timeoutId.current = window.setTimeout(function () {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: false\n      });\n    }, timeout);\n  };\n\n  var handleBlobToBase64 = function handleBlobToBase64(_ref3) {\n    var blob = _ref3.blob,\n        continuous = _ref3.continuous;\n    var reader = new FileReader();\n    reader.readAsDataURL(blob);\n\n    reader.onloadend = function _callee2() {\n      var _audioContextRef$curr3, _googleCloudJson$resu;\n\n      var base64data, sampleRate, audio, config, data, googleCloudRes, googleCloudJson, transcript;\n      return _regeneratorRuntime.async(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              base64data = reader.result;\n              sampleRate = (_audioContextRef$curr3 = audioContextRef.current) == null ? void 0 : _audioContextRef$curr3.sampleRate;\n\n              if (sampleRate && sampleRate > 48000) {\n                sampleRate = 48000;\n              }\n\n              audio = {\n                content: ''\n              };\n              config = _objectSpread({\n                encoding: 'LINEAR16',\n                languageCode: 'en-US',\n                sampleRateHertz: sampleRate\n              }, googleCloudRecognitionConfig);\n              data = {\n                config: config,\n                audio: audio\n              };\n              audio.content = base64data.substr(base64data.indexOf(',') + 1);\n              _context2.next = 9;\n              return _regeneratorRuntime.awrap(fetch(\"https://speech.googleapis.com/v1/speech:recognize?key=\" + googleApiKey, {\n                method: 'POST',\n                body: JSON.stringify(data)\n              }));\n\n            case 9:\n              googleCloudRes = _context2.sent;\n              _context2.next = 12;\n              return _regeneratorRuntime.awrap(googleCloudRes.json());\n\n            case 12:\n              googleCloudJson = _context2.sent;\n\n              if (((_googleCloudJson$resu = googleCloudJson.results) == null ? void 0 : _googleCloudJson$resu.length) > 0) {\n                transcript = googleCloudJson.results[0].alternatives[0].transcript;\n                setLegacyResults(function (prevResults) {\n                  return [].concat(_toConsumableArray(prevResults), [transcript]);\n                });\n                setResults(function (prevResults) {\n                  return [].concat(_toConsumableArray(prevResults), [{\n                    speechBlob: blob,\n                    transcript: transcript,\n                    timestamp: Math.floor(Date.now() / 1000)\n                  }]);\n                });\n              }\n\n              if (continuous) {\n                startSpeechToText();\n              } else {\n                stopMediaStream();\n                setIsRecording(false);\n              }\n\n            case 15:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, null, null, null, Promise);\n    };\n  };\n\n  var stopMediaStream = function stopMediaStream() {\n    var _mediaStream$current;\n\n    (_mediaStream$current = mediaStream.current) == null ? void 0 : _mediaStream$current.getAudioTracks()[0].stop();\n  };\n\n  return {\n    error: error,\n    interimResult: interimResult,\n    isRecording: isRecording,\n    results: useLegacyResults ? legacyResults : results,\n    setResults: setResults,\n    startSpeechToText: startSpeechToText,\n    stopSpeechToText: stopSpeechToText\n  };\n}","map":{"version":3,"names":["useState","useEffect","useRef","Hark","startRecording","stopRecording","isEdgeChromium","navigator","userAgent","indexOf","AudioContext","window","webkitAudioContext","SpeechRecognition","webkitSpeechRecognition","recognition","brave","isBrave","then","bool","useSpeechToText","continuous","crossBrowser","googleApiKey","googleCloudRecognitionConfig","onStartSpeaking","onStoppedSpeaking","speechRecognitionProperties","interimResults","timeout","useOnlyGoogleCloud","useLegacyResults","isRecording","setIsRecording","audioContextRef","legacyResults","setLegacyResults","results","setResults","interimResult","setInterimResult","error","setError","timeoutId","mediaStream","mediaDevices","getUserMedia","console","current","warn","chromeSpeechRecognition","grammars","lang","maxAlternatives","start","onresult","e","result","length","transcript","timestamp","Math","floor","Date","now","isFinal","undefined","prevResults","concatTranscripts","i","resultIndex","onaudiostart","onend","startSpeechToText","state","resume","errHandler","audioContext","stream","clearTimeout","handleRecordingTimeout","stopMediaStream","clone","speechEvents","on","exportWAV","wavCallback","blob","handleBlobToBase64","stopSpeechToText","stop","setTimeout","reader","FileReader","readAsDataURL","onloadend","base64data","sampleRate","audio","content","config","encoding","languageCode","sampleRateHertz","data","substr","fetch","method","body","JSON","stringify","googleCloudRes","json","googleCloudJson","alternatives","speechBlob","getAudioTracks"],"sources":["/Users/sandeepjain/Routine-Remind/screens/StudentScreen/Hooks/index.tsx"],"sourcesContent":["import { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from './recorderHelpers';\n\n// https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\nimport { GoogleCloudRecognitionConfig } from './GoogleCloudRecognitionConfig';\n\n// https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\nexport interface SpeechRecognitionProperties {\n  // continuous: do not pass continuous here, instead pass it as a param to the hook\n  grammars?: SpeechGrammarList;\n  interimResults?: boolean;\n  lang?: string;\n  maxAlternatives?: number;\n}\n\nconst isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\n\ninterface BraveNavigator extends Navigator {\n  brave: {\n    isBrave: () => Promise<boolean>;\n  };\n}\n\nconst AudioContext = window.AudioContext || (window as any).webkitAudioContext;\n\nconst SpeechRecognition =\n  window.SpeechRecognition || (window as any).webkitSpeechRecognition;\n\nlet recognition: SpeechRecognition | null;\n\nexport type ResultType = {\n  speechBlob?: Blob;\n  timestamp: number;\n  transcript: string;\n};\n\n// Set recognition back to null for brave browser due to promise resolving\n// after the conditional on line 31\nif ((navigator as BraveNavigator).brave) {\n  (navigator as BraveNavigator).brave.isBrave().then((bool) => {\n    if (bool) recognition = null;\n  });\n}\n\n// Chromium browsers will have the SpeechRecognition method\n// but do not implement the functionality due to google wanting ðŸ’°\n// this covers new Edge and line 22 covers Brave, the two most popular non-chrome chromium browsers\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\n\nexport interface UseSpeechToTextTypes {\n  continuous?: boolean;\n  crossBrowser?: boolean;\n  googleApiKey?: string;\n  googleCloudRecognitionConfig?: GoogleCloudRecognitionConfig;\n  onStartSpeaking?: () => any;\n  onStoppedSpeaking?: () => any;\n  speechRecognitionProperties?: SpeechRecognitionProperties;\n  timeout?: number;\n  useLegacyResults?: boolean;\n  useOnlyGoogleCloud?: boolean;\n}\n\nexport default function useSpeechToText({\n  continuous,\n  crossBrowser,\n  googleApiKey,\n  googleCloudRecognitionConfig,\n  onStartSpeaking,\n  onStoppedSpeaking,\n  speechRecognitionProperties = { interimResults: true },\n  timeout = 10000,\n  useOnlyGoogleCloud = false,\n  useLegacyResults = true\n}: UseSpeechToTextTypes) {\n  const [isRecording, setIsRecording] = useState(false);\n\n  const audioContextRef = useRef<AudioContext>();\n\n  const [legacyResults, setLegacyResults] = useState<string[]>([]);\n  const [results, setResults] = useState<ResultType[]>([]);\n\n  const [interimResult, setInterimResult] = useState<string | undefined>();\n  const [error, setError] = useState('');\n\n  const timeoutId = useRef<number>();\n  const mediaStream = useRef<MediaStream>();\n\n  useEffect(() => {\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n\n    if (!navigator?.mediaDevices?.getUserMedia) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error(\n        'No google cloud API key was passed, google API will not be able to process speech'\n      );\n    }\n\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n\n    if (useLegacyResults) {\n      console.warn(\n        'react-hook-speech-to-text is using legacy results, pass useLegacyResults: false to the hook to use the new array of objects results. Legacy array of strings results will be removed in a future version.'\n      );\n    }\n  }, []);\n\n  // Chrome Speech Recognition API:\n  // Only supported on Chrome browsers\n  const chromeSpeechRecognition = () => {\n    if (recognition) {\n      // Continuous recording after stopped speaking event\n      if (continuous) recognition.continuous = true;\n\n      const { grammars, interimResults, lang, maxAlternatives } =\n        speechRecognitionProperties || {};\n\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1;\n\n      // start recognition\n      recognition.start();\n\n      // speech successfully translated into text\n      recognition.onresult = (e) => {\n        const result = e.results[e.results.length - 1];\n        const { transcript } = result[0];\n\n        const timestamp = Math.floor(Date.now() / 1000);\n\n        // Allows for realtime speech result UI feedback\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults((prevResults) => [\n              ...prevResults,\n              { transcript, timestamp }\n            ]);\n            setLegacyResults((prevResults) => [...prevResults, transcript]);\n          } else {\n            let concatTranscripts = '';\n\n            // If continuous: e.results will include previous speech results: need to start loop at the current event resultIndex for proper concatenation\n            for (let i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults((prevResults) => [\n            ...prevResults,\n            { transcript, timestamp }\n          ]);\n          setLegacyResults((prevResults) => [...prevResults, transcript]);\n        }\n      };\n\n      recognition.onaudiostart = () => setIsRecording(true);\n\n      // Audio stopped recording or timed out.\n      // Chrome speech auto times-out if no speech after a while\n      recognition.onend = () => {\n        setIsRecording(false);\n      };\n    }\n  };\n\n  const startSpeechToText = async () => {\n    if (!useOnlyGoogleCloud && recognition) {\n      chromeSpeechRecognition();\n      return;\n    }\n\n    if (!crossBrowser && !useOnlyGoogleCloud) {\n      return;\n    }\n\n    // Resume audio context due to google auto play policy\n    // https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n    if (audioContextRef.current?.state === 'suspended') {\n      audioContextRef.current?.resume();\n    }\n\n    const stream = await startRecording({\n      errHandler: () => setError('Microphone permission was denied'),\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    setIsRecording(true);\n\n    // Stop recording if timeout\n    if (timeout) {\n      clearTimeout(timeoutId.current);\n      handleRecordingTimeout();\n    }\n\n    // stop previous mediaStream track if exists\n    if (mediaStream.current) {\n      stopMediaStream();\n    }\n\n    // Clones stream to fix hark bug on Safari\n    mediaStream.current = stream.clone();\n\n    const speechEvents = Hark(mediaStream.current, {\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    speechEvents.on('speaking', () => {\n      if (onStartSpeaking) onStartSpeaking();\n\n      // Clear previous recording timeout on every speech event\n      clearTimeout(timeoutId.current);\n    });\n\n    speechEvents.on('stopped_speaking', () => {\n      if (onStoppedSpeaking) onStoppedSpeaking();\n\n      // Stops current recording and sends audio string to google cloud.\n      // recording will start again after google cloud api\n      // call if `continuous` prop is true. Until the api result\n      // returns, technically the microphone is not being captured again\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) =>\n          handleBlobToBase64({ blob, continuous: continuous || false })\n      });\n    });\n  };\n\n  const stopSpeechToText = () => {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) => handleBlobToBase64({ blob, continuous: false })\n      });\n    }\n  };\n\n  const handleRecordingTimeout = () => {\n    timeoutId.current = window.setTimeout(() => {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({ exportWAV: false });\n    }, timeout);\n  };\n\n  const handleBlobToBase64 = ({\n    blob,\n    continuous\n  }: {\n    blob: Blob;\n    continuous: boolean;\n  }) => {\n    const reader = new FileReader();\n    reader.readAsDataURL(blob);\n\n    reader.onloadend = async () => {\n      const base64data = reader.result as string;\n\n      let sampleRate = audioContextRef.current?.sampleRate;\n\n      // Google only accepts max 48000 sample rate: if\n      // greater recorder js will down-sample to 48000\n      if (sampleRate && sampleRate > 48000) {\n        sampleRate = 48000;\n      }\n\n      const audio = { content: '' };\n\n      const config: GoogleCloudRecognitionConfig = {\n        encoding: 'LINEAR16',\n        languageCode: 'en-US',\n        sampleRateHertz: sampleRate,\n        ...googleCloudRecognitionConfig\n      };\n\n      const data = {\n        config,\n        audio\n      };\n\n      // Gets raw base 64 string data\n      audio.content = base64data.substr(base64data.indexOf(',') + 1);\n\n      const googleCloudRes = await fetch(\n        `https://speech.googleapis.com/v1/speech:recognize?key=${googleApiKey}`,\n        {\n          method: 'POST',\n          body: JSON.stringify(data)\n        }\n      );\n\n      const googleCloudJson = await googleCloudRes.json();\n\n      // Update results state with transcribed text\n      if (googleCloudJson.results?.length > 0) {\n        const { transcript } = googleCloudJson.results[0].alternatives[0];\n\n        setLegacyResults((prevResults) => [...prevResults, transcript]);\n\n        setResults((prevResults) => [\n          ...prevResults,\n          {\n            speechBlob: blob,\n            transcript,\n            timestamp: Math.floor(Date.now() / 1000)\n          }\n        ]);\n      }\n\n      if (continuous) {\n        startSpeechToText();\n      } else {\n        stopMediaStream();\n        setIsRecording(false);\n      }\n    };\n  };\n\n  const stopMediaStream = () => {\n    mediaStream.current?.getAudioTracks()[0].stop();\n  };\n\n  return {\n    error,\n    interimResult,\n    isRecording,\n    results: useLegacyResults ? legacyResults : results,\n    setResults,\n    startSpeechToText,\n    stopSpeechToText\n  };\n}\n"],"mappings":";;;;;;;;;AAAA,SAASA,QAAT,EAAmBC,SAAnB,EAA8BC,MAA9B,QAA4C,OAA5C;AACA,OAAOC,IAAP,MAAiB,MAAjB;AACA,SAASC,cAAT,EAAyBC,aAAzB;AAcA,IAAMC,cAAc,GAAGC,SAAS,CAACC,SAAV,CAAoBC,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAAhE;AAQA,IAAMC,YAAY,GAAGC,MAAM,CAACD,YAAP,IAAwBC,MAAD,CAAgBC,kBAA5D;AAEA,IAAMC,iBAAiB,GACrBF,MAAM,CAACE,iBAAP,IAA6BF,MAAD,CAAgBG,uBAD9C;AAGA,IAAIC,WAAJ;;AAUA,IAAKR,SAAD,CAA8BS,KAAlC,EAAyC;EACtCT,SAAD,CAA8BS,KAA9B,CAAoCC,OAApC,GAA8CC,IAA9C,CAAmD,UAACC,IAAD,EAAU;IAC3D,IAAIA,IAAJ,EAAUJ,WAAW,GAAG,IAAd;EACX,CAFD;AAGD;;AAKD,IAAI,CAACT,cAAD,IAAmBO,iBAAvB,EAA0C;EACxCE,WAAW,GAAG,IAAIF,iBAAJ,EAAd;AACD;;AAeD,eAAe,SAASO,eAAT,OAWU;EAAA,IAVvBC,UAUuB,QAVvBA,UAUuB;EAAA,IATvBC,YASuB,QATvBA,YASuB;EAAA,IARvBC,YAQuB,QARvBA,YAQuB;EAAA,IAPvBC,4BAOuB,QAPvBA,4BAOuB;EAAA,IANvBC,eAMuB,QANvBA,eAMuB;EAAA,IALvBC,iBAKuB,QALvBA,iBAKuB;EAAA,iCAJvBC,2BAIuB;EAAA,IAJvBA,2BAIuB,sCAJO;IAAEC,cAAc,EAAE;EAAlB,CAIP;EAAA,wBAHvBC,OAGuB;EAAA,IAHvBA,OAGuB,6BAHb,KAGa;EAAA,iCAFvBC,kBAEuB;EAAA,IAFvBA,kBAEuB,sCAFF,KAEE;EAAA,iCADvBC,gBACuB;EAAA,IADvBA,gBACuB,sCADJ,IACI;;EACvB,gBAAsC/B,QAAQ,CAAC,KAAD,CAA9C;EAAA;EAAA,IAAOgC,WAAP;EAAA,IAAoBC,cAApB;;EAEA,IAAMC,eAAe,GAAGhC,MAAM,EAA9B;;EAEA,iBAA0CF,QAAQ,CAAW,EAAX,CAAlD;EAAA;EAAA,IAAOmC,aAAP;EAAA,IAAsBC,gBAAtB;;EACA,iBAA8BpC,QAAQ,CAAe,EAAf,CAAtC;EAAA;EAAA,IAAOqC,OAAP;EAAA,IAAgBC,UAAhB;;EAEA,iBAA0CtC,QAAQ,EAAlD;EAAA;EAAA,IAAOuC,aAAP;EAAA,IAAsBC,gBAAtB;;EACA,iBAA0BxC,QAAQ,CAAC,EAAD,CAAlC;EAAA;EAAA,IAAOyC,KAAP;EAAA,IAAcC,QAAd;;EAEA,IAAMC,SAAS,GAAGzC,MAAM,EAAxB;EACA,IAAM0C,WAAW,GAAG1C,MAAM,EAA1B;EAEAD,SAAS,CAAC,YAAM;IAAA;;IACd,IAAI,CAACqB,YAAD,IAAiB,CAACP,WAAtB,EAAmC;MACjC2B,QAAQ,CAAC,oDAAD,CAAR;IACD;;IAED,IAAI,gBAACnC,SAAD,sCAAC,WAAWsC,YAAZ,aAAC,sBAAyBC,YAA1B,CAAJ,EAA4C;MAC1CJ,QAAQ,CAAC,yDAAD,CAAR;IACD;;IAED,IAAI,CAACpB,YAAY,IAAIQ,kBAAjB,KAAwC,CAACP,YAA7C,EAA2D;MACzDwB,OAAO,CAACN,KAAR,CACE,mFADF;IAGD;;IAED,IAAI,CAACP,eAAe,CAACc,OAArB,EAA8B;MAC5Bd,eAAe,CAACc,OAAhB,GAA0B,IAAItC,YAAJ,EAA1B;IACD;;IAED,IAAIqB,gBAAJ,EAAsB;MACpBgB,OAAO,CAACE,IAAR,CACE,2MADF;IAGD;EACF,CAxBQ,EAwBN,EAxBM,CAAT;;EA4BA,IAAMC,uBAAuB,GAAG,SAA1BA,uBAA0B,GAAM;IACpC,IAAInC,WAAJ,EAAiB;MAEf,IAAIM,UAAJ,EAAgBN,WAAW,CAACM,UAAZ,GAAyB,IAAzB;;MAEhB,YACEM,2BAA2B,IAAI,EADjC;MAAA,IAAQwB,QAAR,SAAQA,QAAR;MAAA,IAAkBvB,cAAlB,SAAkBA,cAAlB;MAAA,IAAkCwB,IAAlC,SAAkCA,IAAlC;MAAA,IAAwCC,eAAxC,SAAwCA,eAAxC;;MAGA,IAAIF,QAAJ,EAAcpC,WAAW,CAACoC,QAAZ,GAAuBA,QAAvB;MACd,IAAIC,IAAJ,EAAUrC,WAAW,CAACqC,IAAZ,GAAmBA,IAAnB;MAEVrC,WAAW,CAACa,cAAZ,GAA6BA,cAAc,IAAI,KAA/C;MACAb,WAAW,CAACsC,eAAZ,GAA8BA,eAAe,IAAI,CAAjD;MAGAtC,WAAW,CAACuC,KAAZ;;MAGAvC,WAAW,CAACwC,QAAZ,GAAuB,UAACC,CAAD,EAAO;QAC5B,IAAMC,MAAM,GAAGD,CAAC,CAACnB,OAAF,CAAUmB,CAAC,CAACnB,OAAF,CAAUqB,MAAV,GAAmB,CAA7B,CAAf;QACA,IAAQC,UAAR,GAAuBF,MAAM,CAAC,CAAD,CAA7B,CAAQE,UAAR;QAEA,IAAMC,SAAS,GAAGC,IAAI,CAACC,KAAL,CAAWC,IAAI,CAACC,GAAL,KAAa,IAAxB,CAAlB;;QAGA,IAAIpC,cAAJ,EAAoB;UAClB,IAAI6B,MAAM,CAACQ,OAAX,EAAoB;YAClBzB,gBAAgB,CAAC0B,SAAD,CAAhB;YACA5B,UAAU,CAAC,UAAC6B,WAAD;cAAA,oCACNA,WADM,IAET;gBAAER,UAAU,EAAVA,UAAF;gBAAcC,SAAS,EAATA;cAAd,CAFS;YAAA,CAAD,CAAV;YAIAxB,gBAAgB,CAAC,UAAC+B,WAAD;cAAA,oCAAqBA,WAArB,IAAkCR,UAAlC;YAAA,CAAD,CAAhB;UACD,CAPD,MAOO;YACL,IAAIS,iBAAiB,GAAG,EAAxB;;YAGA,KAAK,IAAIC,CAAC,GAAGb,CAAC,CAACc,WAAf,EAA4BD,CAAC,GAAGb,CAAC,CAACnB,OAAF,CAAUqB,MAA1C,EAAkDW,CAAC,EAAnD,EAAuD;cACrDD,iBAAiB,IAAIZ,CAAC,CAACnB,OAAF,CAAUgC,CAAV,EAAa,CAAb,EAAgBV,UAArC;YACD;;YAEDnB,gBAAgB,CAAC4B,iBAAD,CAAhB;UACD;QACF,CAlBD,MAkBO;UACL9B,UAAU,CAAC,UAAC6B,WAAD;YAAA,oCACNA,WADM,IAET;cAAER,UAAU,EAAVA,UAAF;cAAcC,SAAS,EAATA;YAAd,CAFS;UAAA,CAAD,CAAV;UAIAxB,gBAAgB,CAAC,UAAC+B,WAAD;YAAA,oCAAqBA,WAArB,IAAkCR,UAAlC;UAAA,CAAD,CAAhB;QACD;MACF,CAhCD;;MAkCA5C,WAAW,CAACwD,YAAZ,GAA2B;QAAA,OAAMtC,cAAc,CAAC,IAAD,CAApB;MAAA,CAA3B;;MAIAlB,WAAW,CAACyD,KAAZ,GAAoB,YAAM;QACxBvC,cAAc,CAAC,KAAD,CAAd;MACD,CAFD;IAGD;EACF,CA5DD;;EA8DA,IAAMwC,iBAAiB,GAAG;IAAA;;IAAA;;IAAA;MAAA;QAAA;UAAA;YAAA,MACpB,CAAC3C,kBAAD,IAAuBf,WADH;cAAA;cAAA;YAAA;;YAEtBmC,uBAAuB;YAFD;;UAAA;YAAA,MAMpB,CAAC5B,YAAD,IAAiB,CAACQ,kBANE;cAAA;cAAA;YAAA;;YAAA;;UAAA;YAYxB,IAAI,0BAAAI,eAAe,CAACc,OAAhB,2CAAyB0B,KAAzB,MAAmC,WAAvC,EAAoD;cAClD,0BAAAxC,eAAe,CAACc,OAAhB,4CAAyB2B,MAAzB;YACD;;YAduB;YAAA,iCAgBHvE,cAAc,CAAC;cAClCwE,UAAU,EAAE;gBAAA,OAAMlC,QAAQ,CAAC,kCAAD,CAAd;cAAA,CADsB;cAElCmC,YAAY,EAAE3C,eAAe,CAACc;YAFI,CAAD,CAhBX;;UAAA;YAgBlB8B,MAhBkB;YAqBxB7C,cAAc,CAAC,IAAD,CAAd;;YAGA,IAAIJ,OAAJ,EAAa;cACXkD,YAAY,CAACpC,SAAS,CAACK,OAAX,CAAZ;cACAgC,sBAAsB;YACvB;;YAGD,IAAIpC,WAAW,CAACI,OAAhB,EAAyB;cACvBiC,eAAe;YAChB;;YAGDrC,WAAW,CAACI,OAAZ,GAAsB8B,MAAM,CAACI,KAAP,EAAtB;YAEMC,YArCkB,GAqCHhF,IAAI,CAACyC,WAAW,CAACI,OAAb,EAAsB;cAC7C6B,YAAY,EAAE3C,eAAe,CAACc;YADe,CAAtB,CArCD;YAyCxBmC,YAAY,CAACC,EAAb,CAAgB,UAAhB,EAA4B,YAAM;cAChC,IAAI3D,eAAJ,EAAqBA,eAAe;cAGpCsD,YAAY,CAACpC,SAAS,CAACK,OAAX,CAAZ;YACD,CALD;YAOAmC,YAAY,CAACC,EAAb,CAAgB,kBAAhB,EAAoC,YAAM;cACxC,IAAI1D,iBAAJ,EAAuBA,iBAAiB;cAMxCrB,aAAa,CAAC;gBACZgF,SAAS,EAAE,IADC;gBAEZC,WAAW,EAAE,qBAACC,IAAD;kBAAA,OACXC,kBAAkB,CAAC;oBAAED,IAAI,EAAJA,IAAF;oBAAQlE,UAAU,EAAEA,UAAU,IAAI;kBAAlC,CAAD,CADP;gBAAA;cAFD,CAAD,CAAb;YAKD,CAZD;;UAhDwB;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAA1B;;EA+DA,IAAMoE,gBAAgB,GAAG,SAAnBA,gBAAmB,GAAM;IAC7B,IAAI1E,WAAW,IAAI,CAACe,kBAApB,EAAwC;MACtCf,WAAW,CAAC2E,IAAZ;IACD,CAFD,MAEO;MACLzD,cAAc,CAAC,KAAD,CAAd;MACAgD,eAAe;MACf5E,aAAa,CAAC;QACZgF,SAAS,EAAE,IADC;QAEZC,WAAW,EAAE,qBAACC,IAAD;UAAA,OAAUC,kBAAkB,CAAC;YAAED,IAAI,EAAJA,IAAF;YAAQlE,UAAU,EAAE;UAApB,CAAD,CAA5B;QAAA;MAFD,CAAD,CAAb;IAID;EACF,CAXD;;EAaA,IAAM2D,sBAAsB,GAAG,SAAzBA,sBAAyB,GAAM;IACnCrC,SAAS,CAACK,OAAV,GAAoBrC,MAAM,CAACgF,UAAP,CAAkB,YAAM;MAC1C1D,cAAc,CAAC,KAAD,CAAd;MACAgD,eAAe;MACf5E,aAAa,CAAC;QAAEgF,SAAS,EAAE;MAAb,CAAD,CAAb;IACD,CAJmB,EAIjBxD,OAJiB,CAApB;EAKD,CAND;;EAQA,IAAM2D,kBAAkB,GAAG,SAArBA,kBAAqB,QAMrB;IAAA,IALJD,IAKI,SALJA,IAKI;IAAA,IAJJlE,UAII,SAJJA,UAII;IACJ,IAAMuE,MAAM,GAAG,IAAIC,UAAJ,EAAf;IACAD,MAAM,CAACE,aAAP,CAAqBP,IAArB;;IAEAK,MAAM,CAACG,SAAP,GAAmB;MAAA;;MAAA;MAAA;QAAA;UAAA;YAAA;cACXC,UADW,GACEJ,MAAM,CAACnC,MADT;cAGbwC,UAHa,6BAGA/D,eAAe,CAACc,OAHhB,qBAGA,uBAAyBiD,UAHzB;;cAOjB,IAAIA,UAAU,IAAIA,UAAU,GAAG,KAA/B,EAAsC;gBACpCA,UAAU,GAAG,KAAb;cACD;;cAEKC,KAXW,GAWH;gBAAEC,OAAO,EAAE;cAAX,CAXG;cAaXC,MAbW;gBAcfC,QAAQ,EAAE,UAdK;gBAefC,YAAY,EAAE,OAfC;gBAgBfC,eAAe,EAAEN;cAhBF,GAiBZzE,4BAjBY;cAoBXgF,IApBW,GAoBJ;gBACXJ,MAAM,EAANA,MADW;gBAEXF,KAAK,EAALA;cAFW,CApBI;cA0BjBA,KAAK,CAACC,OAAN,GAAgBH,UAAU,CAACS,MAAX,CAAkBT,UAAU,CAACvF,OAAX,CAAmB,GAAnB,IAA0B,CAA5C,CAAhB;cA1BiB;cAAA,iCA4BYiG,KAAK,4DACyBnF,YADzB,EAEhC;gBACEoF,MAAM,EAAE,MADV;gBAEEC,IAAI,EAAEC,IAAI,CAACC,SAAL,CAAeN,IAAf;cAFR,CAFgC,CA5BjB;;YAAA;cA4BXO,cA5BW;cAAA;cAAA,iCAoCaA,cAAc,CAACC,IAAf,EApCb;;YAAA;cAoCXC,eApCW;;cAuCjB,IAAI,0BAAAA,eAAe,CAAC5E,OAAhB,2CAAyBqB,MAAzB,IAAkC,CAAtC,EAAyC;gBAC/BC,UAD+B,GAChBsD,eAAe,CAAC5E,OAAhB,CAAwB,CAAxB,EAA2B6E,YAA3B,CAAwC,CAAxC,CADgB,CAC/BvD,UAD+B;gBAGvCvB,gBAAgB,CAAC,UAAC+B,WAAD;kBAAA,oCAAqBA,WAArB,IAAkCR,UAAlC;gBAAA,CAAD,CAAhB;gBAEArB,UAAU,CAAC,UAAC6B,WAAD;kBAAA,oCACNA,WADM,IAET;oBACEgD,UAAU,EAAE5B,IADd;oBAEE5B,UAAU,EAAVA,UAFF;oBAGEC,SAAS,EAAEC,IAAI,CAACC,KAAL,CAAWC,IAAI,CAACC,GAAL,KAAa,IAAxB;kBAHb,CAFS;gBAAA,CAAD,CAAV;cAQD;;cAED,IAAI3C,UAAJ,EAAgB;gBACdoD,iBAAiB;cAClB,CAFD,MAEO;gBACLQ,eAAe;gBACfhD,cAAc,CAAC,KAAD,CAAd;cACD;;YA3DgB;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA,CAAnB;EA6DD,CAvED;;EAyEA,IAAMgD,eAAe,GAAG,SAAlBA,eAAkB,GAAM;IAAA;;IAC5B,wBAAArC,WAAW,CAACI,OAAZ,0CAAqBoE,cAArB,GAAsC,CAAtC,EAAyC1B,IAAzC;EACD,CAFD;;EAIA,OAAO;IACLjD,KAAK,EAALA,KADK;IAELF,aAAa,EAAbA,aAFK;IAGLP,WAAW,EAAXA,WAHK;IAILK,OAAO,EAAEN,gBAAgB,GAAGI,aAAH,GAAmBE,OAJvC;IAKLC,UAAU,EAAVA,UALK;IAMLmC,iBAAiB,EAAjBA,iBANK;IAOLgB,gBAAgB,EAAhBA;EAPK,CAAP;AASD"},"metadata":{},"sourceType":"module"}