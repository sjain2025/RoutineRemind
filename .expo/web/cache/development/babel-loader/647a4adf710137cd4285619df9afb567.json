{"ast":null,"code":"import _defineProperty from \"@babel/runtime/helpers/defineProperty\";\nimport _toConsumableArray from \"@babel/runtime/helpers/toConsumableArray\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from \"./recorderHelpers\";\n\nvar isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\nvar AudioContext = window.AudioContext || window.webkitAudioContext;\nvar SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nvar recognition;\nif (navigator.brave) {\n  navigator.brave.isBrave().then(function (bool) {\n    if (bool) recognition = null;\n  });\n}\n\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\nexport default function useSpeechToText(_ref) {\n  var continuous = _ref.continuous,\n    crossBrowser = _ref.crossBrowser,\n    googleApiKey = _ref.googleApiKey,\n    googleCloudRecognitionConfig = _ref.googleCloudRecognitionConfig,\n    onStartSpeaking = _ref.onStartSpeaking,\n    onStoppedSpeaking = _ref.onStoppedSpeaking,\n    _ref$speechRecognitio = _ref.speechRecognitionProperties,\n    speechRecognitionProperties = _ref$speechRecognitio === void 0 ? {\n      interimResults: true\n    } : _ref$speechRecognitio,\n    _ref$timeout = _ref.timeout,\n    timeout = _ref$timeout === void 0 ? 10000 : _ref$timeout,\n    _ref$useOnlyGoogleClo = _ref.useOnlyGoogleCloud,\n    useOnlyGoogleCloud = _ref$useOnlyGoogleClo === void 0 ? false : _ref$useOnlyGoogleClo,\n    _ref$useLegacyResults = _ref.useLegacyResults,\n    useLegacyResults = _ref$useLegacyResults === void 0 ? true : _ref$useLegacyResults;\n  var _useState = useState(false),\n    _useState2 = _slicedToArray(_useState, 2),\n    isRecording = _useState2[0],\n    setIsRecording = _useState2[1];\n  var audioContextRef = useRef();\n  var _useState3 = useState([]),\n    _useState4 = _slicedToArray(_useState3, 2),\n    legacyResults = _useState4[0],\n    setLegacyResults = _useState4[1];\n  var _useState5 = useState([]),\n    _useState6 = _slicedToArray(_useState5, 2),\n    results = _useState6[0],\n    setResults = _useState6[1];\n  var _useState7 = useState(),\n    _useState8 = _slicedToArray(_useState7, 2),\n    interimResult = _useState8[0],\n    setInterimResult = _useState8[1];\n  var _useState9 = useState(''),\n    _useState10 = _slicedToArray(_useState9, 2),\n    error = _useState10[0],\n    setError = _useState10[1];\n  var timeoutId = useRef();\n  var mediaStream = useRef();\n  useEffect(function () {\n    var _navigator, _navigator$mediaDevic;\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n    if (!((_navigator = navigator) != null && (_navigator$mediaDevic = _navigator.mediaDevices) != null && _navigator$mediaDevic.getUserMedia)) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error('No google cloud API key was passed, google API will not be able to process speech');\n    }\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n    if (useLegacyResults) {\n      console.warn('react-hook-speech-to-text is using legacy results, pass useLegacyResults: false to the hook to use the new array of objects results. Legacy array of strings results will be removed in a future version.');\n    }\n  }, []);\n\n  var chromeSpeechRecognition = function chromeSpeechRecognition() {\n    if (recognition) {\n      if (continuous) recognition.continuous = true;\n      var _ref2 = speechRecognitionProperties || {},\n        grammars = _ref2.grammars,\n        interimResults = _ref2.interimResults,\n        lang = _ref2.lang,\n        maxAlternatives = _ref2.maxAlternatives;\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1;\n\n      recognition.start();\n\n      recognition.onresult = function (e) {\n        var result = e.results[e.results.length - 1];\n        var transcript = result[0].transcript;\n        var timestamp = Math.floor(Date.now() / 1000);\n\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults(function (prevResults) {\n              return [].concat(_toConsumableArray(prevResults), [{\n                transcript: transcript,\n                timestamp: timestamp\n              }]);\n            });\n            setLegacyResults(function (prevResults) {\n              return [].concat(_toConsumableArray(prevResults), [transcript]);\n            });\n          } else {\n            var concatTranscripts = '';\n\n            for (var i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults(function (prevResults) {\n            return [].concat(_toConsumableArray(prevResults), [{\n              transcript: transcript,\n              timestamp: timestamp\n            }]);\n          });\n          setLegacyResults(function (prevResults) {\n            return [].concat(_toConsumableArray(prevResults), [transcript]);\n          });\n        }\n      };\n      recognition.onaudiostart = function () {\n        return setIsRecording(true);\n      };\n\n      recognition.onend = function () {\n        setIsRecording(false);\n      };\n    }\n  };\n  var startSpeechToText = function _callee() {\n    var _audioContextRef$curr;\n    var _audioContextRef$curr2, stream, speechEvents;\n    return _regeneratorRuntime.async(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (!(!useOnlyGoogleCloud && recognition)) {\n              _context.next = 3;\n              break;\n            }\n            chromeSpeechRecognition();\n            return _context.abrupt(\"return\");\n          case 3:\n            if (!(!crossBrowser && !useOnlyGoogleCloud)) {\n              _context.next = 5;\n              break;\n            }\n            return _context.abrupt(\"return\");\n          case 5:\n            if (((_audioContextRef$curr = audioContextRef.current) == null ? void 0 : _audioContextRef$curr.state) === 'suspended') {\n              (_audioContextRef$curr2 = audioContextRef.current) == null ? void 0 : _audioContextRef$curr2.resume();\n            }\n            _context.next = 8;\n            return _regeneratorRuntime.awrap(startRecording({\n              errHandler: function errHandler() {\n                return setError('Microphone permission was denied');\n              },\n              audioContext: audioContextRef.current\n            }));\n          case 8:\n            stream = _context.sent;\n            setIsRecording(true);\n\n            if (timeout) {\n              clearTimeout(timeoutId.current);\n              handleRecordingTimeout();\n            }\n\n            if (mediaStream.current) {\n              stopMediaStream();\n            }\n\n            mediaStream.current = stream.clone();\n            speechEvents = Hark(mediaStream.current, {\n              audioContext: audioContextRef.current\n            });\n            speechEvents.on('speaking', function () {\n              if (onStartSpeaking) onStartSpeaking();\n\n              clearTimeout(timeoutId.current);\n            });\n            speechEvents.on('stopped_speaking', function () {\n              if (onStoppedSpeaking) onStoppedSpeaking();\n\n              stopRecording({\n                exportWAV: true,\n                wavCallback: function wavCallback(blob) {\n                  return handleBlobToBase64({\n                    blob: blob,\n                    continuous: continuous || false\n                  });\n                }\n              });\n            });\n          case 16:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, null, null, null, Promise);\n  };\n  var stopSpeechToText = function stopSpeechToText() {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: function wavCallback(blob) {\n          return handleBlobToBase64({\n            blob: blob,\n            continuous: false\n          });\n        }\n      });\n    }\n  };\n  var handleRecordingTimeout = function handleRecordingTimeout() {\n    timeoutId.current = window.setTimeout(function () {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: false\n      });\n    }, timeout);\n  };\n  var handleBlobToBase64 = function handleBlobToBase64(_ref3) {\n    var blob = _ref3.blob,\n      continuous = _ref3.continuous;\n    var reader = new FileReader();\n    reader.readAsDataURL(blob);\n    reader.onloadend = function _callee2() {\n      var _audioContextRef$curr3, _googleCloudJson$resu;\n      var base64data, sampleRate, audio, config, data, googleCloudRes, googleCloudJson, transcript;\n      return _regeneratorRuntime.async(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              base64data = reader.result;\n              sampleRate = (_audioContextRef$curr3 = audioContextRef.current) == null ? void 0 : _audioContextRef$curr3.sampleRate;\n              if (sampleRate && sampleRate > 48000) {\n                sampleRate = 48000;\n              }\n              audio = {\n                content: ''\n              };\n              config = _objectSpread({\n                encoding: 'LINEAR16',\n                languageCode: 'en-US',\n                sampleRateHertz: sampleRate\n              }, googleCloudRecognitionConfig);\n              data = {\n                config: config,\n                audio: audio\n              };\n              audio.content = base64data.substr(base64data.indexOf(',') + 1);\n              _context2.next = 9;\n              return _regeneratorRuntime.awrap(fetch(\"https://speech.googleapis.com/v1/speech:recognize?key=\" + googleApiKey, {\n                method: 'POST',\n                body: JSON.stringify(data)\n              }));\n            case 9:\n              googleCloudRes = _context2.sent;\n              _context2.next = 12;\n              return _regeneratorRuntime.awrap(googleCloudRes.json());\n            case 12:\n              googleCloudJson = _context2.sent;\n              if (((_googleCloudJson$resu = googleCloudJson.results) == null ? void 0 : _googleCloudJson$resu.length) > 0) {\n                transcript = googleCloudJson.results[0].alternatives[0].transcript;\n                setLegacyResults(function (prevResults) {\n                  return [].concat(_toConsumableArray(prevResults), [transcript]);\n                });\n                setResults(function (prevResults) {\n                  return [].concat(_toConsumableArray(prevResults), [{\n                    speechBlob: blob,\n                    transcript: transcript,\n                    timestamp: Math.floor(Date.now() / 1000)\n                  }]);\n                });\n              }\n              if (continuous) {\n                startSpeechToText();\n              } else {\n                stopMediaStream();\n                setIsRecording(false);\n              }\n            case 15:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, null, null, null, Promise);\n    };\n  };\n  var stopMediaStream = function stopMediaStream() {\n    var _mediaStream$current;\n    (_mediaStream$current = mediaStream.current) == null ? void 0 : _mediaStream$current.getAudioTracks()[0].stop();\n  };\n  return {\n    error: error,\n    interimResult: interimResult,\n    isRecording: isRecording,\n    results: useLegacyResults ? legacyResults : results,\n    setResults: setResults,\n    startSpeechToText: startSpeechToText,\n    stopSpeechToText: stopSpeechToText\n  };\n}","map":{"version":3,"names":["useState","useEffect","useRef","Hark","startRecording","stopRecording","isEdgeChromium","navigator","userAgent","indexOf","AudioContext","window","webkitAudioContext","SpeechRecognition","webkitSpeechRecognition","recognition","brave","isBrave","then","bool","useSpeechToText","continuous","crossBrowser","googleApiKey","googleCloudRecognitionConfig","onStartSpeaking","onStoppedSpeaking","speechRecognitionProperties","interimResults","timeout","useOnlyGoogleCloud","useLegacyResults","isRecording","setIsRecording","audioContextRef","legacyResults","setLegacyResults","results","setResults","interimResult","setInterimResult","error","setError","timeoutId","mediaStream","mediaDevices","getUserMedia","console","current","warn","chromeSpeechRecognition","grammars","lang","maxAlternatives","start","onresult","e","result","length","transcript","timestamp","Math","floor","Date","now","isFinal","undefined","prevResults","concatTranscripts","i","resultIndex","onaudiostart","onend","startSpeechToText","state","resume","errHandler","audioContext","stream","clearTimeout","handleRecordingTimeout","stopMediaStream","clone","speechEvents","on","exportWAV","wavCallback","blob","handleBlobToBase64","stopSpeechToText","stop","setTimeout","reader","FileReader","readAsDataURL","onloadend","base64data","sampleRate","audio","content","config","encoding","languageCode","sampleRateHertz","data","substr","fetch","method","body","JSON","stringify","googleCloudRes","json","googleCloudJson","alternatives","speechBlob","getAudioTracks"],"sources":["C:/Users/netra/Documents/GitHub/RoutineRemind/screens/StudentScreen/Hooks/index.tsx"],"sourcesContent":["import { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from './recorderHelpers';\n\n// https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\nimport { GoogleCloudRecognitionConfig } from './GoogleCloudRecognitionConfig';\n\n// https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\nexport interface SpeechRecognitionProperties {\n  // continuous: do not pass continuous here, instead pass it as a param to the hook\n  grammars?: SpeechGrammarList;\n  interimResults?: boolean;\n  lang?: string;\n  maxAlternatives?: number;\n}\n\nconst isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\n\ninterface BraveNavigator extends Navigator {\n  brave: {\n    isBrave: () => Promise<boolean>;\n  };\n}\n\nconst AudioContext = window.AudioContext || (window as any).webkitAudioContext;\n\nconst SpeechRecognition =\n  window.SpeechRecognition || (window as any).webkitSpeechRecognition;\n\nlet recognition: SpeechRecognition | null;\n\nexport type ResultType = {\n  speechBlob?: Blob;\n  timestamp: number;\n  transcript: string;\n};\n\n// Set recognition back to null for brave browser due to promise resolving\n// after the conditional on line 31\nif ((navigator as BraveNavigator).brave) {\n  (navigator as BraveNavigator).brave.isBrave().then((bool) => {\n    if (bool) recognition = null;\n  });\n}\n\n// Chromium browsers will have the SpeechRecognition method\n// but do not implement the functionality due to google wanting ðŸ’°\n// this covers new Edge and line 22 covers Brave, the two most popular non-chrome chromium browsers\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\n\nexport interface UseSpeechToTextTypes {\n  continuous?: boolean;\n  crossBrowser?: boolean;\n  googleApiKey?: string;\n  googleCloudRecognitionConfig?: GoogleCloudRecognitionConfig;\n  onStartSpeaking?: () => any;\n  onStoppedSpeaking?: () => any;\n  speechRecognitionProperties?: SpeechRecognitionProperties;\n  timeout?: number;\n  useLegacyResults?: boolean;\n  useOnlyGoogleCloud?: boolean;\n}\n\nexport default function useSpeechToText({\n  continuous,\n  crossBrowser,\n  googleApiKey,\n  googleCloudRecognitionConfig,\n  onStartSpeaking,\n  onStoppedSpeaking,\n  speechRecognitionProperties = { interimResults: true },\n  timeout = 10000,\n  useOnlyGoogleCloud = false,\n  useLegacyResults = true\n}: UseSpeechToTextTypes) {\n  const [isRecording, setIsRecording] = useState(false);\n\n  const audioContextRef = useRef<AudioContext>();\n\n  const [legacyResults, setLegacyResults] = useState<string[]>([]);\n  const [results, setResults] = useState<ResultType[]>([]);\n\n  const [interimResult, setInterimResult] = useState<string | undefined>();\n  const [error, setError] = useState('');\n\n  const timeoutId = useRef<number>();\n  const mediaStream = useRef<MediaStream>();\n\n  useEffect(() => {\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n\n    if (!navigator?.mediaDevices?.getUserMedia) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error(\n        'No google cloud API key was passed, google API will not be able to process speech'\n      );\n    }\n\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n\n    if (useLegacyResults) {\n      console.warn(\n        'react-hook-speech-to-text is using legacy results, pass useLegacyResults: false to the hook to use the new array of objects results. Legacy array of strings results will be removed in a future version.'\n      );\n    }\n  }, []);\n\n  // Chrome Speech Recognition API:\n  // Only supported on Chrome browsers\n  const chromeSpeechRecognition = () => {\n    if (recognition) {\n      // Continuous recording after stopped speaking event\n      if (continuous) recognition.continuous = true;\n\n      const { grammars, interimResults, lang, maxAlternatives } =\n        speechRecognitionProperties || {};\n\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1;\n\n      // start recognition\n      recognition.start();\n\n      // speech successfully translated into text\n      recognition.onresult = (e) => {\n        const result = e.results[e.results.length - 1];\n        const { transcript } = result[0];\n\n        const timestamp = Math.floor(Date.now() / 1000);\n\n        // Allows for realtime speech result UI feedback\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults((prevResults) => [\n              ...prevResults,\n              { transcript, timestamp }\n            ]);\n            setLegacyResults((prevResults) => [...prevResults, transcript]);\n          } else {\n            let concatTranscripts = '';\n\n            // If continuous: e.results will include previous speech results: need to start loop at the current event resultIndex for proper concatenation\n            for (let i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults((prevResults) => [\n            ...prevResults,\n            { transcript, timestamp }\n          ]);\n          setLegacyResults((prevResults) => [...prevResults, transcript]);\n        }\n      };\n\n      recognition.onaudiostart = () => setIsRecording(true);\n\n      // Audio stopped recording or timed out.\n      // Chrome speech auto times-out if no speech after a while\n      recognition.onend = () => {\n        setIsRecording(false);\n      };\n    }\n  };\n\n  const startSpeechToText = async () => {\n    if (!useOnlyGoogleCloud && recognition) {\n      chromeSpeechRecognition();\n      return;\n    }\n\n    if (!crossBrowser && !useOnlyGoogleCloud) {\n      return;\n    }\n\n    // Resume audio context due to google auto play policy\n    // https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n    if (audioContextRef.current?.state === 'suspended') {\n      audioContextRef.current?.resume();\n    }\n\n    const stream = await startRecording({\n      errHandler: () => setError('Microphone permission was denied'),\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    setIsRecording(true);\n\n    // Stop recording if timeout\n    if (timeout) {\n      clearTimeout(timeoutId.current);\n      handleRecordingTimeout();\n    }\n\n    // stop previous mediaStream track if exists\n    if (mediaStream.current) {\n      stopMediaStream();\n    }\n\n    // Clones stream to fix hark bug on Safari\n    mediaStream.current = stream.clone();\n\n    const speechEvents = Hark(mediaStream.current, {\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    speechEvents.on('speaking', () => {\n      if (onStartSpeaking) onStartSpeaking();\n\n      // Clear previous recording timeout on every speech event\n      clearTimeout(timeoutId.current);\n    });\n\n    speechEvents.on('stopped_speaking', () => {\n      if (onStoppedSpeaking) onStoppedSpeaking();\n\n      // Stops current recording and sends audio string to google cloud.\n      // recording will start again after google cloud api\n      // call if `continuous` prop is true. Until the api result\n      // returns, technically the microphone is not being captured again\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) =>\n          handleBlobToBase64({ blob, continuous: continuous || false })\n      });\n    });\n  };\n\n  const stopSpeechToText = () => {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) => handleBlobToBase64({ blob, continuous: false })\n      });\n    }\n  };\n\n  const handleRecordingTimeout = () => {\n    timeoutId.current = window.setTimeout(() => {\n      setIsRecording(false);\n      stopMediaStream();\n      stopRecording({ exportWAV: false });\n    }, timeout);\n  };\n\n  const handleBlobToBase64 = ({\n    blob,\n    continuous\n  }: {\n    blob: Blob;\n    continuous: boolean;\n  }) => {\n    const reader = new FileReader();\n    reader.readAsDataURL(blob);\n\n    reader.onloadend = async () => {\n      const base64data = reader.result as string;\n\n      let sampleRate = audioContextRef.current?.sampleRate;\n\n      // Google only accepts max 48000 sample rate: if\n      // greater recorder js will down-sample to 48000\n      if (sampleRate && sampleRate > 48000) {\n        sampleRate = 48000;\n      }\n\n      const audio = { content: '' };\n\n      const config: GoogleCloudRecognitionConfig = {\n        encoding: 'LINEAR16',\n        languageCode: 'en-US',\n        sampleRateHertz: sampleRate,\n        ...googleCloudRecognitionConfig\n      };\n\n      const data = {\n        config,\n        audio\n      };\n\n      // Gets raw base 64 string data\n      audio.content = base64data.substr(base64data.indexOf(',') + 1);\n\n      const googleCloudRes = await fetch(\n        `https://speech.googleapis.com/v1/speech:recognize?key=${googleApiKey}`,\n        {\n          method: 'POST',\n          body: JSON.stringify(data)\n        }\n      );\n\n      const googleCloudJson = await googleCloudRes.json();\n\n      // Update results state with transcribed text\n      if (googleCloudJson.results?.length > 0) {\n        const { transcript } = googleCloudJson.results[0].alternatives[0];\n\n        setLegacyResults((prevResults) => [...prevResults, transcript]);\n\n        setResults((prevResults) => [\n          ...prevResults,\n          {\n            speechBlob: blob,\n            transcript,\n            timestamp: Math.floor(Date.now() / 1000)\n          }\n        ]);\n      }\n\n      if (continuous) {\n        startSpeechToText();\n      } else {\n        stopMediaStream();\n        setIsRecording(false);\n      }\n    };\n  };\n\n  const stopMediaStream = () => {\n    mediaStream.current?.getAudioTracks()[0].stop();\n  };\n\n  return {\n    error,\n    interimResult,\n    isRecording,\n    results: useLegacyResults ? legacyResults : results,\n    setResults,\n    startSpeechToText,\n    stopSpeechToText\n  };\n}\n"],"mappings":";;;;;;AAAA,SAASA,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AACnD,OAAOC,IAAI,MAAM,MAAM;AACvB,SAASC,cAAc,EAAEC,aAAa;;AActC,IAAMC,cAAc,GAAGC,SAAS,CAACC,SAAS,CAACC,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;AAQjE,IAAMC,YAAY,GAAGC,MAAM,CAACD,YAAY,IAAKC,MAAM,CAASC,kBAAkB;AAE9E,IAAMC,iBAAiB,GACrBF,MAAM,CAACE,iBAAiB,IAAKF,MAAM,CAASG,uBAAuB;AAErE,IAAIC,WAAqC;AAUzC,IAAKR,SAAS,CAAoBS,KAAK,EAAE;EACtCT,SAAS,CAAoBS,KAAK,CAACC,OAAO,EAAE,CAACC,IAAI,CAAC,UAACC,IAAI,EAAK;IAC3D,IAAIA,IAAI,EAAEJ,WAAW,GAAG,IAAI;EAC9B,CAAC,CAAC;AACJ;;AAKA,IAAI,CAACT,cAAc,IAAIO,iBAAiB,EAAE;EACxCE,WAAW,GAAG,IAAIF,iBAAiB,EAAE;AACvC;AAeA,eAAe,SAASO,eAAe,OAWd;EAAA,IAVvBC,UAAU,QAAVA,UAAU;IACVC,YAAY,QAAZA,YAAY;IACZC,YAAY,QAAZA,YAAY;IACZC,4BAA4B,QAA5BA,4BAA4B;IAC5BC,eAAe,QAAfA,eAAe;IACfC,iBAAiB,QAAjBA,iBAAiB;IAAA,6BACjBC,2BAA2B;IAA3BA,2BAA2B,sCAAG;MAAEC,cAAc,EAAE;IAAK,CAAC;IAAA,oBACtDC,OAAO;IAAPA,OAAO,6BAAG,KAAK;IAAA,6BACfC,kBAAkB;IAAlBA,kBAAkB,sCAAG,KAAK;IAAA,6BAC1BC,gBAAgB;IAAhBA,gBAAgB,sCAAG,IAAI;EAEvB,gBAAsC/B,QAAQ,CAAC,KAAK,CAAC;IAAA;IAA9CgC,WAAW;IAAEC,cAAc;EAElC,IAAMC,eAAe,GAAGhC,MAAM,EAAgB;EAE9C,iBAA0CF,QAAQ,CAAW,EAAE,CAAC;IAAA;IAAzDmC,aAAa;IAAEC,gBAAgB;EACtC,iBAA8BpC,QAAQ,CAAe,EAAE,CAAC;IAAA;IAAjDqC,OAAO;IAAEC,UAAU;EAE1B,iBAA0CtC,QAAQ,EAAsB;IAAA;IAAjEuC,aAAa;IAAEC,gBAAgB;EACtC,iBAA0BxC,QAAQ,CAAC,EAAE,CAAC;IAAA;IAA/ByC,KAAK;IAAEC,QAAQ;EAEtB,IAAMC,SAAS,GAAGzC,MAAM,EAAU;EAClC,IAAM0C,WAAW,GAAG1C,MAAM,EAAe;EAEzCD,SAAS,CAAC,YAAM;IAAA;IACd,IAAI,CAACqB,YAAY,IAAI,CAACP,WAAW,EAAE;MACjC2B,QAAQ,CAAC,oDAAoD,CAAC;IAChE;IAEA,IAAI,gBAACnC,SAAS,sCAAT,WAAWsC,YAAY,aAAvB,sBAAyBC,YAAY,GAAE;MAC1CJ,QAAQ,CAAC,yDAAyD,CAAC;IACrE;IAEA,IAAI,CAACpB,YAAY,IAAIQ,kBAAkB,KAAK,CAACP,YAAY,EAAE;MACzDwB,OAAO,CAACN,KAAK,CACX,mFAAmF,CACpF;IACH;IAEA,IAAI,CAACP,eAAe,CAACc,OAAO,EAAE;MAC5Bd,eAAe,CAACc,OAAO,GAAG,IAAItC,YAAY,EAAE;IAC9C;IAEA,IAAIqB,gBAAgB,EAAE;MACpBgB,OAAO,CAACE,IAAI,CACV,2MAA2M,CAC5M;IACH;EACF,CAAC,EAAE,EAAE,CAAC;;EAIN,IAAMC,uBAAuB,GAAG,SAA1BA,uBAAuB,GAAS;IACpC,IAAInC,WAAW,EAAE;MAEf,IAAIM,UAAU,EAAEN,WAAW,CAACM,UAAU,GAAG,IAAI;MAE7C,YACEM,2BAA2B,IAAI,CAAC,CAAC;QAD3BwB,QAAQ,SAARA,QAAQ;QAAEvB,cAAc,SAAdA,cAAc;QAAEwB,IAAI,SAAJA,IAAI;QAAEC,eAAe,SAAfA,eAAe;MAGvD,IAAIF,QAAQ,EAAEpC,WAAW,CAACoC,QAAQ,GAAGA,QAAQ;MAC7C,IAAIC,IAAI,EAAErC,WAAW,CAACqC,IAAI,GAAGA,IAAI;MAEjCrC,WAAW,CAACa,cAAc,GAAGA,cAAc,IAAI,KAAK;MACpDb,WAAW,CAACsC,eAAe,GAAGA,eAAe,IAAI,CAAC;;MAGlDtC,WAAW,CAACuC,KAAK,EAAE;;MAGnBvC,WAAW,CAACwC,QAAQ,GAAG,UAACC,CAAC,EAAK;QAC5B,IAAMC,MAAM,GAAGD,CAAC,CAACnB,OAAO,CAACmB,CAAC,CAACnB,OAAO,CAACqB,MAAM,GAAG,CAAC,CAAC;QAC9C,IAAQC,UAAU,GAAKF,MAAM,CAAC,CAAC,CAAC,CAAxBE,UAAU;QAElB,IAAMC,SAAS,GAAGC,IAAI,CAACC,KAAK,CAACC,IAAI,CAACC,GAAG,EAAE,GAAG,IAAI,CAAC;;QAG/C,IAAIpC,cAAc,EAAE;UAClB,IAAI6B,MAAM,CAACQ,OAAO,EAAE;YAClBzB,gBAAgB,CAAC0B,SAAS,CAAC;YAC3B5B,UAAU,CAAC,UAAC6B,WAAW;cAAA,oCAClBA,WAAW,IACd;gBAAER,UAAU,EAAVA,UAAU;gBAAEC,SAAS,EAATA;cAAU,CAAC;YAAA,CAC1B,CAAC;YACFxB,gBAAgB,CAAC,UAAC+B,WAAW;cAAA,oCAASA,WAAW,IAAER,UAAU;YAAA,CAAC,CAAC;UACjE,CAAC,MAAM;YACL,IAAIS,iBAAiB,GAAG,EAAE;;YAG1B,KAAK,IAAIC,CAAC,GAAGb,CAAC,CAACc,WAAW,EAAED,CAAC,GAAGb,CAAC,CAACnB,OAAO,CAACqB,MAAM,EAAEW,CAAC,EAAE,EAAE;cACrDD,iBAAiB,IAAIZ,CAAC,CAACnB,OAAO,CAACgC,CAAC,CAAC,CAAC,CAAC,CAAC,CAACV,UAAU;YACjD;YAEAnB,gBAAgB,CAAC4B,iBAAiB,CAAC;UACrC;QACF,CAAC,MAAM;UACL9B,UAAU,CAAC,UAAC6B,WAAW;YAAA,oCAClBA,WAAW,IACd;cAAER,UAAU,EAAVA,UAAU;cAAEC,SAAS,EAATA;YAAU,CAAC;UAAA,CAC1B,CAAC;UACFxB,gBAAgB,CAAC,UAAC+B,WAAW;YAAA,oCAASA,WAAW,IAAER,UAAU;UAAA,CAAC,CAAC;QACjE;MACF,CAAC;MAED5C,WAAW,CAACwD,YAAY,GAAG;QAAA,OAAMtC,cAAc,CAAC,IAAI,CAAC;MAAA;;MAIrDlB,WAAW,CAACyD,KAAK,GAAG,YAAM;QACxBvC,cAAc,CAAC,KAAK,CAAC;MACvB,CAAC;IACH;EACF,CAAC;EAED,IAAMwC,iBAAiB,GAAG;IAAA;IAAA;IAAA;MAAA;QAAA;UAAA;YAAA,MACpB,CAAC3C,kBAAkB,IAAIf,WAAW;cAAA;cAAA;YAAA;YACpCmC,uBAAuB,EAAE;YAAC;UAAA;YAAA,MAIxB,CAAC5B,YAAY,IAAI,CAACQ,kBAAkB;cAAA;cAAA;YAAA;YAAA;UAAA;YAMxC,IAAI,0BAAAI,eAAe,CAACc,OAAO,qBAAvB,sBAAyB0B,KAAK,MAAK,WAAW,EAAE;cAClD,0BAAAxC,eAAe,CAACc,OAAO,qBAAvB,uBAAyB2B,MAAM,EAAE;YACnC;YAAC;YAAA,iCAEoBvE,cAAc,CAAC;cAClCwE,UAAU,EAAE;gBAAA,OAAMlC,QAAQ,CAAC,kCAAkC,CAAC;cAAA;cAC9DmC,YAAY,EAAE3C,eAAe,CAACc;YAChC,CAAC,CAAC;UAAA;YAHI8B,MAAM;YAKZ7C,cAAc,CAAC,IAAI,CAAC;;YAGpB,IAAIJ,OAAO,EAAE;cACXkD,YAAY,CAACpC,SAAS,CAACK,OAAO,CAAC;cAC/BgC,sBAAsB,EAAE;YAC1B;;YAGA,IAAIpC,WAAW,CAACI,OAAO,EAAE;cACvBiC,eAAe,EAAE;YACnB;;YAGArC,WAAW,CAACI,OAAO,GAAG8B,MAAM,CAACI,KAAK,EAAE;YAE9BC,YAAY,GAAGhF,IAAI,CAACyC,WAAW,CAACI,OAAO,EAAE;cAC7C6B,YAAY,EAAE3C,eAAe,CAACc;YAChC,CAAC,CAAC;YAEFmC,YAAY,CAACC,EAAE,CAAC,UAAU,EAAE,YAAM;cAChC,IAAI3D,eAAe,EAAEA,eAAe,EAAE;;cAGtCsD,YAAY,CAACpC,SAAS,CAACK,OAAO,CAAC;YACjC,CAAC,CAAC;YAEFmC,YAAY,CAACC,EAAE,CAAC,kBAAkB,EAAE,YAAM;cACxC,IAAI1D,iBAAiB,EAAEA,iBAAiB,EAAE;;cAM1CrB,aAAa,CAAC;gBACZgF,SAAS,EAAE,IAAI;gBACfC,WAAW,EAAE,qBAACC,IAAI;kBAAA,OAChBC,kBAAkB,CAAC;oBAAED,IAAI,EAAJA,IAAI;oBAAElE,UAAU,EAAEA,UAAU,IAAI;kBAAM,CAAC,CAAC;gBAAA;cACjE,CAAC,CAAC;YACJ,CAAC,CAAC;UAAC;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CACJ;EAED,IAAMoE,gBAAgB,GAAG,SAAnBA,gBAAgB,GAAS;IAC7B,IAAI1E,WAAW,IAAI,CAACe,kBAAkB,EAAE;MACtCf,WAAW,CAAC2E,IAAI,EAAE;IACpB,CAAC,MAAM;MACLzD,cAAc,CAAC,KAAK,CAAC;MACrBgD,eAAe,EAAE;MACjB5E,aAAa,CAAC;QACZgF,SAAS,EAAE,IAAI;QACfC,WAAW,EAAE,qBAACC,IAAI;UAAA,OAAKC,kBAAkB,CAAC;YAAED,IAAI,EAAJA,IAAI;YAAElE,UAAU,EAAE;UAAM,CAAC,CAAC;QAAA;MACxE,CAAC,CAAC;IACJ;EACF,CAAC;EAED,IAAM2D,sBAAsB,GAAG,SAAzBA,sBAAsB,GAAS;IACnCrC,SAAS,CAACK,OAAO,GAAGrC,MAAM,CAACgF,UAAU,CAAC,YAAM;MAC1C1D,cAAc,CAAC,KAAK,CAAC;MACrBgD,eAAe,EAAE;MACjB5E,aAAa,CAAC;QAAEgF,SAAS,EAAE;MAAM,CAAC,CAAC;IACrC,CAAC,EAAExD,OAAO,CAAC;EACb,CAAC;EAED,IAAM2D,kBAAkB,GAAG,SAArBA,kBAAkB,QAMlB;IAAA,IALJD,IAAI,SAAJA,IAAI;MACJlE,UAAU,SAAVA,UAAU;IAKV,IAAMuE,MAAM,GAAG,IAAIC,UAAU,EAAE;IAC/BD,MAAM,CAACE,aAAa,CAACP,IAAI,CAAC;IAE1BK,MAAM,CAACG,SAAS,GAAG;MAAA;MAAA;MAAA;QAAA;UAAA;YAAA;cACXC,UAAU,GAAGJ,MAAM,CAACnC,MAAM;cAE5BwC,UAAU,6BAAG/D,eAAe,CAACc,OAAO,qBAAvB,uBAAyBiD,UAAU;cAIpD,IAAIA,UAAU,IAAIA,UAAU,GAAG,KAAK,EAAE;gBACpCA,UAAU,GAAG,KAAK;cACpB;cAEMC,KAAK,GAAG;gBAAEC,OAAO,EAAE;cAAG,CAAC;cAEvBC,MAAoC;gBACxCC,QAAQ,EAAE,UAAU;gBACpBC,YAAY,EAAE,OAAO;gBACrBC,eAAe,EAAEN;cAAU,GACxBzE,4BAA4B;cAG3BgF,IAAI,GAAG;gBACXJ,MAAM,EAANA,MAAM;gBACNF,KAAK,EAALA;cACF,CAAC;cAGDA,KAAK,CAACC,OAAO,GAAGH,UAAU,CAACS,MAAM,CAACT,UAAU,CAACvF,OAAO,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;cAAC;cAAA,iCAElCiG,KAAK,4DACyBnF,YAAY,EACrE;gBACEoF,MAAM,EAAE,MAAM;gBACdC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAACN,IAAI;cAC3B,CAAC,CACF;YAAA;cANKO,cAAc;cAAA;cAAA,iCAQUA,cAAc,CAACC,IAAI,EAAE;YAAA;cAA7CC,eAAe;cAGrB,IAAI,0BAAAA,eAAe,CAAC5E,OAAO,qBAAvB,sBAAyBqB,MAAM,IAAG,CAAC,EAAE;gBAC/BC,UAAU,GAAKsD,eAAe,CAAC5E,OAAO,CAAC,CAAC,CAAC,CAAC6E,YAAY,CAAC,CAAC,CAAC,CAAzDvD,UAAU;gBAElBvB,gBAAgB,CAAC,UAAC+B,WAAW;kBAAA,oCAASA,WAAW,IAAER,UAAU;gBAAA,CAAC,CAAC;gBAE/DrB,UAAU,CAAC,UAAC6B,WAAW;kBAAA,oCAClBA,WAAW,IACd;oBACEgD,UAAU,EAAE5B,IAAI;oBAChB5B,UAAU,EAAVA,UAAU;oBACVC,SAAS,EAAEC,IAAI,CAACC,KAAK,CAACC,IAAI,CAACC,GAAG,EAAE,GAAG,IAAI;kBACzC,CAAC;gBAAA,CACF,CAAC;cACJ;cAEA,IAAI3C,UAAU,EAAE;gBACdoD,iBAAiB,EAAE;cACrB,CAAC,MAAM;gBACLQ,eAAe,EAAE;gBACjBhD,cAAc,CAAC,KAAK,CAAC;cACvB;YAAC;YAAA;cAAA;UAAA;QAAA;MAAA;IAAA,CACF;EACH,CAAC;EAED,IAAMgD,eAAe,GAAG,SAAlBA,eAAe,GAAS;IAAA;IAC5B,wBAAArC,WAAW,CAACI,OAAO,qBAAnB,qBAAqBoE,cAAc,EAAE,CAAC,CAAC,CAAC,CAAC1B,IAAI,EAAE;EACjD,CAAC;EAED,OAAO;IACLjD,KAAK,EAALA,KAAK;IACLF,aAAa,EAAbA,aAAa;IACbP,WAAW,EAAXA,WAAW;IACXK,OAAO,EAAEN,gBAAgB,GAAGI,aAAa,GAAGE,OAAO;IACnDC,UAAU,EAAVA,UAAU;IACVmC,iBAAiB,EAAjBA,iBAAiB;IACjBgB,gBAAgB,EAAhBA;EACF,CAAC;AACH"},"metadata":{},"sourceType":"module"}